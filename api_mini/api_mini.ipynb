{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Mini-Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focus on equities data from the Frankfurt Stock Exchange (FSE), analyzing the stock prices of a company called Carl Zeiss Meditec (stock ticker AFX_X).\n",
    "\n",
    "Quandl Usage: https://docs.quandl.com/docs/in-depth-usage\n",
    "\n",
    "Quandl Parameters: https://docs.quandl.com/docs/parameters-2\n",
    "\n",
    "Quandl Error codes: https://docs.quandl.com/docs/error-codes\n",
    "\n",
    "GET composition:\n",
    "https://www.quandl.com/api/v3/datasets/{database_code}/{dataset_code}/data.{return_format}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started: Calling the API\n",
    "\n",
    "    # import modules\n",
    "    import requests\n",
    "\n",
    "    # API key for Qunadl - variable constant in upper case\n",
    "    API_KEY = ''\n",
    "\n",
    "The GET composition for the Quandl API is:\n",
    "\n",
    "(base url) + (database code) + (dataset code) + (return format) + (api_key) + (params)\n",
    "\n",
    "(base url) https://www.quandl.com/api/v3/datasets/ + (database code) FSE/ + (dataset code) AFX_X/ + (return format) data.json + (api_key) ?API_KEY + (params) ...\n",
    "\n",
    "For now, we'll use a constant for the url with our database code set to *Frankfurt Stock Exchange (FSE)*, and the dataset code set to *Carl Zeiss Meditec (AFX_X)*. In the future, we could make this more robust by using variables for the database code & dataset code, as parse together the URL string based on user inputs, etc.\n",
    "\n",
    "    # assign the API's GET url to variable url\n",
    "    url = 'https://www.quandl.com/api/v3/datasets/FSE/AFX_X/data.json'\n",
    "\n",
    "A full list of parameters can be found here (https://docs.quandl.com/docs/parameters-2). To begin, we'll test the API call and return the headers using just the API_KEY as a parameter.\n",
    "\n",
    "    # dictionary of parameters\n",
    "    params = dict(api_key=API_KEY)\n",
    "\n",
    "We'll create the variable `res` to hold the response from the Quandl API.\n",
    "\n",
    "    # use variable 'res' to hold the response\n",
    "    res = requests.get(url, params=params)\n",
    "\n",
    "Next, add in a response confirmation conditional and the response status code.\n",
    "\n",
    "    # evaluate response\n",
    "    if res:\n",
    "        print('Response OK')\n",
    "    else:\n",
    "        print('Response Failed')\n",
    "    print(res.status_code)\n",
    "\n",
    "Finally, print the headers for more information about the API call.\n",
    "\n",
    "    # review headers\n",
    "    print(res.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response OK\n",
      "200\n",
      "{'Date': 'Thu, 26 Mar 2020 20:34:28 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Set-Cookie': '__cfduid=d0365e913d0d937758042ba15ff4273e31585254867; expires=Sat, 25-Apr-20 20:34:27 GMT; path=/; domain=.quandl.com; HttpOnly; SameSite=Lax', 'Allow': 'GET, HEAD, POST, PUT, DELETE, OPTIONS, PATCH', 'Cache-Control': 'max-age=0, private, must-revalidate', 'Content-Encoding': 'gzip', 'ETag': 'W/\"e10c3bb2c5f49536ce7d14e10278b446\"', 'Vary': 'Origin', 'X-Content-Type-Options': 'nosniff', 'X-Frame-Options': 'SAMEORIGIN', 'X-Rack-CORS': 'miss; no-origin', 'X-RateLimit-Limit': '50000', 'X-RateLimit-Remaining': '49980', 'X-Request-Id': '9e9d0941-677a-49dc-8dd7-746ce7090af1', 'X-Runtime': '0.830617', 'X-XSS-Protection': '1; mode=block', 'CF-Cache-Status': 'DYNAMIC', 'Expect-CT': 'max-age=604800, report-uri=\"https://report-uri.cloudflare.com/cdn-cgi/beacon/expect-ct\"', 'Server': 'cloudflare', 'CF-RAY': '57a3a708bd30ec4e-DFW'}\n"
     ]
    }
   ],
   "source": [
    "# API key for Qunadl - variable constant in upper case\n",
    "API_KEY = 'xRBPkDXL3JtxX9HRxAQ-'\n",
    "\n",
    "# assign the API's GET url to variable url\n",
    "url = 'https://www.quandl.com/api/v3/datasets/FSE/AFX_X/data.json'\n",
    "\n",
    "# dictionary of parameters\n",
    "params = dict(api_key=API_KEY)\n",
    "\n",
    "# use variable 'res' to hold the response\n",
    "res = requests.get(url, params=params)\n",
    "\n",
    "# evaluate response\n",
    "if res:\n",
    "    print('Response OK')\n",
    "else:\n",
    "    print('Response Failed')\n",
    "print(res.status_code)\n",
    "\n",
    "# review headers\n",
    "print(res.headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Great!* Headers can return useful information about the API. For example, since I called the Quandl GET API, the *Content-Type* returned will be a `application/json` with a *charset type* as `utf-8`.\n",
    "\n",
    "*Also*, since I'm working with a trial API key, the headers `X-RateLimit-Limit` and `X-RateLimit-Remaining` will be of use to me as well!\n",
    "\n",
    "Next, let's return a row of data by adding in the `limit` parameter to our `params` dictionary, and passing it '1' to get the latest row.\n",
    "\n",
    "    # dictionary of parameters\n",
    "    params = dict(api_key=API_KEY, limit='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of parameters\n",
    "params = dict(api_key=API_KEY, limit='1')\n",
    "\n",
    "# send the GET request for 1 row of return\n",
    "res = requests.get(url, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"dataset_data\":{\"limit\":1,\"transform\":null,\"column_index\":null,\"column_names\":[\"Date\",\"Open\",\"High\",\"Low\",\"Close\",\"Change\",\"Traded Volume\",\"Turnover\",\"Last Price of the Day\",\"Daily Traded Units\",\"Daily Turnover\"],\"start_date\":\"2000-06-07\",\"end_date\":\"2020-03-25\",\"frequency\":\"daily\",\"data\":[[\"2020-03-25\",82.5,90.4,80.6,83.1,null,284087.0,23870691.15,null,null,null]],\"collapse\":null,\"order\":null}}\n"
     ]
    }
   ],
   "source": [
    "# print the response\n",
    "print(res.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Holy keys!* Remember: the json file type is a series of nested *key: value* pairs. Knowing that a json formatted file can be mapped to a dictionary will come in handy when we solve the project tasks below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Collect data from the Franfurt Stock Exchange, for the ticker AFX_X, for the whole year 2017 (keep in mind that the date format is YYYY-MM-DD).\n",
    "\n",
    "In order to collect data for the whole year, let's pull some of the time-series parameters from the **quandl documentation**.\n",
    "\n",
    "| Parameter | Required | Type | Values | Description |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| start_date | no | string | yyyy-mm-dd | Retrieve data rows on and after the specified start date. |\n",
    "| end_date | no | string | yyyy-mm-dd | Retrieve data rows up to and including the specified end date. |\n",
    "\n",
    "In order to accomplish this, we'll update our `params` variable to include the `start_date` and `end_date` parameters, then pass it to the `.get()` parameter `params=`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of parameters\n",
    "params = dict(api_key=API_KEY, start_date='2017-01-01', end_date='2017-12-31')\n",
    "\n",
    "# send the GET request for 1 row of return\n",
    "res = requests.get(url, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the response code to see if the GET request was received:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response OK\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# evaluate response\n",
    "if res:\n",
    "    print('Response OK')\n",
    "else:\n",
    "    print('Response Failed')\n",
    "print(res.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert the returned JSON object into a Python dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the json file type is formatted as a dictionary, all we'll need to do here is:\n",
    "1. Encode our response as *json* with `.json()`\n",
    "2. Pass the response as an argument to the `dict()` constructor\n",
    "\n",
    "This will take all of the *key: value* pairs within the json-encoded response and map them as a dictionary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode response as json\n",
    "jres = res.json()\n",
    "\n",
    "# create dictionary\n",
    "d = dict(jres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Since we explored the API returns earlier, we know that there was a `start_date` and an `end_date` return. Since the response has nested values, we'll need to reference each key in order to get to the lower hierarchy of values.\n",
    "\n",
    "Let's print the values for these keys to see if our dataset contains all of the 2017 requested data. We can also count the amount of returns to see how many returns came in. According to Wikipedia via Google, 2017 had 251 trading days in the US stock market!\n",
    "\n",
    "![US Stock Market 2017 trading days](https://github.com/jameshollisandrew/springboard_mini_projects/blob/master/api_mini/trading_days.PNG?raw=true \"trading days\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-01\n",
      "2017-12-31\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "# check start_date field of the response\n",
    "print(d['dataset_data']['start_date'])\n",
    "\n",
    "# check end_date field of the response\n",
    "print(d['dataset_data']['end_date'])\n",
    "\n",
    "# check the length of the data responses\n",
    "print(len(d['dataset_data']['data']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *255...Close enough!*\n",
    "\n",
    "> moving forward, let's draw up a quick custom function that we can use to build dictionaries from the API returns.\n",
    "\n",
    "Since we'll be changing the parameters up as needed, let's set the function parameters to take two variables: the parameters to pass to the GET request, and the name of the dictionary we want to create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict(params):\n",
    "    \"\"\"Pass parameters to this function for the Quandl GET API\n",
    "       to return a dictionary of the 'data' nested lists made\n",
    "       from the API's json response\"\"\"\n",
    "    # use variable 'F_res' to hold the response\n",
    "    f_res = requests.get(url, params=params)\n",
    "\n",
    "    # encode response as json\n",
    "    f_json = f_res.json()\n",
    "    \n",
    "    f_dict = dict(f_json)\n",
    "    \n",
    "    # return dictionary\n",
    "    return dict(f_dict['dataset_data']['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate what the highest and lowest opening prices were for the stock in this period.\n",
    "We'll answer this question in three steps:\n",
    "1. Identify which column index relates to the *opening prices*, *date* by checking the `column_names` response key\n",
    "2. Loop through each data entry, checking for the highest, lowest value; then saving the `Date` and `Open` price to variables\n",
    "3. Return the highest & lowest opening prices by day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Open', 'High', 'Low', 'Close', 'Change', 'Traded Volume', 'Turnover', 'Last Price of the Day', 'Daily Traded Units', 'Daily Turnover']\n"
     ]
    }
   ],
   "source": [
    "# check column names\n",
    "print(d['dataset_data']['column_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Date` and `Open` will be the 0 and 1 index values in each of the `data` dictionary lists.\n",
    "\n",
    "> Did you catch the double brackets earlier when we peeked at the API return structure? That was an indication that the data returned was a *list of lists*. We'll keep that in mind when building our loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'NoneType' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-29dd663d0242>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# if open price (op) is greater than stored highest; save price & date\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mop\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0moh\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mh_price\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mh_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'NoneType' and 'float'"
     ]
    }
   ],
   "source": [
    "# create variable for the returned data\n",
    "data_list = d['dataset_data']['data']\n",
    "\n",
    "# create highest values\n",
    "h_price = 0.0\n",
    "h_date = ''\n",
    "\n",
    "# create lowest values\n",
    "l_price = 0.0\n",
    "l_date = ''\n",
    "\n",
    "# take each price entry from the data list and compare it to the \n",
    "for entry in data_list:\n",
    "    op = entry[1]\n",
    "    oh = h_price\n",
    "    ol = l_price\n",
    "\n",
    "    # if open price (op) is greater than stored highest; save price & date\n",
    "    if op > oh:\n",
    "        h_price = op\n",
    "        h_date = entry[0]\n",
    "    \n",
    "    # if stored lowest is greater than open price (op); save price & date\n",
    "    if ol > op:\n",
    "        l_price = op\n",
    "        l_date = entry[0]\n",
    "    \n",
    "print('The highest open price in 2017 was {0}, and occurred on {1}.'.format(h_price, h_date))\n",
    "print('The lowest open price in 2017 was {0}, and occurred on {1}.'.format(l_price, l_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Uh oh!* A **TypeError** at the beginning of our first conditional. Since we're populating the variables with the opening prices returned from the API query, there's a good chance it's an issue there. \n",
    "\n",
    "> Another hint is in the *TypeError* return script: ...'NoneType'... suggests we might have a null value populated on the iteration that set off the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2017-05-01', None, 42.245, 41.655, 41.72, -0.44, 86348.0, 3606589.0, None, None, None]\n",
      "['2017-04-17', None, 42.48, 41.985, 42.2, None, 88416.0, 3734717.0, None, None, None]\n",
      "['2017-04-14', None, 42.48, 41.985, 42.2, None, 88416.0, 3734717.0, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "# take each price entry from the data list and compare it to the \n",
    "for entry in data_list:\n",
    "    op = entry[1]\n",
    "    oh = h_price\n",
    "    ol = l_price\n",
    "    \n",
    "    # insert our 'try' flag for error catching\n",
    "    try:\n",
    "\n",
    "        # if open price (op) is greater than stored highest; save price & date\n",
    "        if op > oh:\n",
    "            h_price = op\n",
    "            h_date = entry[0]\n",
    "\n",
    "        # if stored lowest is greater than open price (op); save price & date\n",
    "        if ol > op:\n",
    "            l_price = op\n",
    "            l_date = entry[0]\n",
    "    \n",
    "    except TypeError:\n",
    "        print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *For some dates we don't have an opening price!* \n",
    "While this discovery would be great for further investigation, let's finish answering the question. To do this, we'll add a condition that will `continue` with the next iterate if the `type != float`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest open price in 2017 was 53.11, and occurred on 2017-12-14.\n",
      "The lowest open price in 2017 was 34.00, and occurred on 2017-01-24.\n"
     ]
    }
   ],
   "source": [
    "# create variable for the returned data\n",
    "data_list = d['dataset_data']['data']\n",
    "\n",
    "# create highest values\n",
    "h_price = data_list[0][1]\n",
    "h_date = data_list[0][0]\n",
    "\n",
    "# create lowest values\n",
    "l_price = data_list[0][1]\n",
    "l_date = data_list[0][0]\n",
    "\n",
    "# take each price entry from the data list and compare it to the \n",
    "for entry in data_list:\n",
    "    op = entry[1]\n",
    "    oh = h_price\n",
    "    ol = l_price\n",
    "\n",
    "    # continue clause to bypass None values\n",
    "    if type(op) != float:\n",
    "        continue\n",
    "    \n",
    "    # if open price (op) is greater than stored highest; save price & date\n",
    "    if op > oh:\n",
    "        h_price = op\n",
    "        h_date = entry[0]\n",
    "    \n",
    "    # if stored lowest is greater than open price (op); save price & date\n",
    "    if ol > op:\n",
    "        l_price = op\n",
    "        l_date = entry[0]\n",
    "\n",
    "# print answer\n",
    "print('The highest open price in 2017 was {0}, and occurred on {1}.'.format((\"%.2f\" % h_price), h_date))\n",
    "print('The lowest open price in 2017 was {0}, and occurred on {1}.'.format((\"%.2f\" % l_price), l_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Great!*\n",
    "\n",
    "> In the printout, we standardized the value format with the string `(\"%.2f\" % variable)`. We'll use this again throughout the project to keep the price printouts limited to 2 floats.\n",
    "\n",
    "Another alternative option is to use the list functions `max()` and `min()` on a list of the opening prices. To do this, we would:\n",
    "1. Loop through the data *list of lists* and create a list of the price values and a list of the dates\n",
    "2. Save the highest and lowest prices to variables\n",
    "3. Use the index position of the highest, lowest prices from the price list to return the dates from the date list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest open price in 2017 was 53.11, and occurred on 2017-12-14.\n",
      "The lowest open price in 2017 was 34.00, and occurred on 2017-01-24.\n"
     ]
    }
   ],
   "source": [
    "# initialize lists\n",
    "price_list = []\n",
    "date_list = []\n",
    "\n",
    "# create list of open prices\n",
    "for entry in data_list:\n",
    "\n",
    "    # continue clause to bypass None values\n",
    "    if type(entry[1]) != float:\n",
    "        continue\n",
    "    \n",
    "    # append the open price to the list\n",
    "    price_list.append(entry[1])\n",
    "    \n",
    "    # append the date to the list\n",
    "    date_list.append(entry[0])\n",
    "\n",
    "# save highest, lowest price to variables\n",
    "h_price = max(price_list)\n",
    "l_price = min(price_list)\n",
    "\n",
    "# use index position of price in price_list as an index call to the date_list\n",
    "h_date = date_list[price_list.index(h_price)]\n",
    "l_date = date_list[price_list.index(l_price)]\n",
    "\n",
    "# print answer\n",
    "print('The highest open price in 2017 was {0}, and occurred on {1}.'.format((\"%.2f\" % h_price), h_date))\n",
    "print('The lowest open price in 2017 was {0}, and occurred on {1}.'.format((\"%.2f\" % l_price), l_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Sometimes duplicate values might occur. To double check, let's use the `.count` list method and pass our highest, lowest prices to make sure they only occur once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(price_list.count(h_price))\n",
    "print(price_list.count(l_price))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Only 1! Let's move on!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. What was the largest change in any one day (based on High and Low price)?\n",
    "For this question, we'll need to: \n",
    "1. Iterate through each list in the data *list of lists*\n",
    "2. Calculate the difference as *high* - *low*\n",
    "3. Append the difference to a list\n",
    "4. Get the max() value from the difference list\n",
    "\n",
    "In the last problem, we used a standard *for loop* to solve the problem. This time around, let's do it with ***list comprehensions***. \n",
    "\n",
    "The general syntax for a list comprehension is:\n",
    "\n",
    "[ **output** *for clause* ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest change in any one day was 2.81, and occurred on 2017-05-11.\n"
     ]
    }
   ],
   "source": [
    "# create list of changes\n",
    "daily_changes = [entry[2]-entry[3] for entry in data_list]\n",
    "\n",
    "# return largest change\n",
    "h_change = max(daily_changes)\n",
    "\n",
    "# create date list\n",
    "date_list = [entry[0] for entry in data_list]\n",
    "\n",
    "# use index position of price in as an index call to the date_list\n",
    "change_date = date_list[daily_changes.index(h_change)]\n",
    "\n",
    "# print answer\n",
    "print('The largest change in any one day was {0}, and occurred on {1}.'.format((\"%.2f\" % h_change), change_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. What was the largest change between any two days (based on Closing Price)?\n",
    "In order to calculate the change between two days, we'll need to subtract *day 0* closing price from *day 1* closing price. We'll reference that return as *day 1* change.\n",
    "\n",
    "The closing price is in the 5th position in the list, or *index 4*.\n",
    "\n",
    "To solve this question, we will:\n",
    "1. Create a list of closing values\n",
    "2. Create a list of 'yesterday's close' by copying the closing value list and removing the last index value\n",
    "3. Create a list of 'today's close' by copying the closing value list, beginning on index position 1\n",
    "4. Initialize an empty list to catch the changes\n",
    "5. Zip the today, yesterday lists and iterate through the pairs, calculating the difference\n",
    "6. Within the zipped list, append each difference to the closing changes list\n",
    "7. Return the max change between any two days using `.max()` on the closing changes list\n",
    "8. Using the max value as an index call, return the date that the max difference occurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest change between any two days was 2.56, and occurred on 2017-08-09.\n"
     ]
    }
   ],
   "source": [
    "# create list of changes\n",
    "close_list = [entry[4] for entry in reversed(data_list)]\n",
    "\n",
    "# remove the last day from the close list\n",
    "close_yest = close_list[:-1].copy()\n",
    "\n",
    "# remove the first day from the close list\n",
    "close_today = close_list[1:].copy()\n",
    "\n",
    "# initalize empty list\n",
    "closing_changes = []\n",
    "\n",
    "# calculate change from zipped lists, append closing_changes\n",
    "for t, y in zip(close_today, close_yest):\n",
    "    change = t-y\n",
    "    closing_changes.append(change)\n",
    "\n",
    "# initialize list, fill starting value\n",
    "largest_index = 0\n",
    "largest_change = closing_changes[0]\n",
    "\n",
    "for idx, x in enumerate(closing_changes):\n",
    "    if abs(x) > largest_change:\n",
    "        largest_change = abs(x)\n",
    "        largest_index = idx\n",
    "\n",
    "# create date list\n",
    "date_list = [entry[0] for entry in reversed(data_list)]\n",
    "\n",
    "# use index position + 1 to offset index adjustment as an index call to the date_list\n",
    "change_date = date_list[largest_index + 1]\n",
    "\n",
    "# print answer\n",
    "print('The largest change between any two days was {0}, and occurred on {1}.'.format((\"%.2f\" % largest_change), change_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we offset the index for the close_today list, we're technically starting with the date_list index position 1. To compensate for this, we've added 1 to the index call from date_list to, 'realign' the indices.\n",
    ">\n",
    "> #### *That was kind of messy though.* Let's try it again, but let's make a call to the API using the `transform` argument to calculate the day over day change for us. We'll also use our custom function and a cleaner looping process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5B. What was the largest change between any two days (based on Closing Price)?\n",
    "For the next API call, we'll be adding arguments for the `column_index=` and `transform=` parameters.\n",
    "\n",
    "| Parameter | Required | Type | Values | Description |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "|column_index | no | int |  | Request a specific column. Column 0 is the date column and is always returned. Data begins at column 1. |\n",
    "| transform | no | string | none, diff, rdiff, rdiff_from, cumul, normalize | Perform elementary calculations on the data prior to downloading. Default is none. |\n",
    "\n",
    "From the Transformations Table:\n",
    "\n",
    "| Name | Effect | Formula |\n",
    "| :--- | :--- | :--- |\n",
    "| none | no effect | z[t] = y[t] |\n",
    "| diff | row-on-row change | z[t] = y[t] – y[t-1] |\n",
    "\n",
    "Okie dokie! So, to answer Question 5 again with the improvements we've discussed, let's:\n",
    "1. Add the `column_index=, transform=` parameters, passing the arguments **4** to subselect the closing price column and **diff** to return the row-on-row change\n",
    "2. Pass the new params to our custom function to return a dictionary of the data nested values as a dictionary\n",
    "3. Loop over the dictionary values (i.e. the closing changes) and compare absolute values to return the largest change\n",
    "4. Return largest change and date to variables, and pass them to the answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of parameters\n",
    "params = dict(api_key=API_KEY, start_date='2017-01-01', end_date='2017-12-31', column_index=4, transform='diff')\n",
    "\n",
    "# make a closing change dict\n",
    "closing_change_dict = make_dict(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest change between any two days was 2.56, and occurred on 2017-08-09.\n"
     ]
    }
   ],
   "source": [
    "largest_change_value = 0\n",
    "largest_change_date = ''\n",
    "\n",
    "# loop through dictionary items, return largest change, date\n",
    "for k, v in closing_change_dict.items():\n",
    "    if abs(v) > largest_change_value:\n",
    "        largest_change_value = abs(v)\n",
    "        largest_change_date = k\n",
    "\n",
    "# print answer\n",
    "print('The largest change between any two days was {0}, and occurred on {1}.'.format((\"%.2f\" % largest_change_value), largest_change_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### *Much cleaner.* Using the API to calculate the day-to-day difference, a custom function to make the nested data into a dictionary, and then iterating over its items is a lot more controlled than our previous answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. What was the average daily trading volume during this year?\n",
    "Daily trading volume occurs in the 7th position, or *index 6*. This will go pretty fast - we'll just need to:\n",
    "1. Create a list of the daily trading volume values\n",
    "2. Calculate the average with `sum()` / `len()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average daily trading volume during 2017 was 89124.34.\n"
     ]
    }
   ],
   "source": [
    "# create list of daily volumes\n",
    "daily_volume = [entry[6] for entry in data_list]\n",
    "\n",
    "# calculate average\n",
    "annual_volume_avg = sum(daily_volume) / len(daily_volume)\n",
    "\n",
    "# print answer\n",
    "print('The average daily trading volume during 2017 was {}.'.format((\"%.2f\" % annual_volume_avg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. (Optional) What was the median trading volume during this year. (Note: you may need to implement your own function for calculating the median.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median trading volume during 2017 was 76600.0.\n"
     ]
    }
   ],
   "source": [
    "# create sorted list\n",
    "ordered_volume = daily_volume.copy()\n",
    "ordered_volume.sort()\n",
    "\n",
    "# get the number of values in the list\n",
    "length = len(ordered_volume)\n",
    "\n",
    "# take the middle of the length, rounded\n",
    "median_index = round(length / 2)\n",
    "\n",
    "# pass the median index position to the ordered list\n",
    "median = ordered_volume[median_index]\n",
    "\n",
    "# print answer\n",
    "print('The median trading volume during 2017 was {}.'.format(median))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
